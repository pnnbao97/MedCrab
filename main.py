import gradio as gr
from medcrab import MedCrabTranslator
import torch
import re
import time
from threading import Thread
from queue import Queue

# --- 1. SETUP MODEL ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ“± Device selected: {device}")

translator = MedCrabTranslator(device=device)

# --- 2. HELPER FUNCTIONS ---

def split_by_sentences(text: str, max_words: int = 100):
    """
    Chia vÄƒn báº£n thÃ nh cÃ¡c chunk
    Tráº£ vá» list of tuples: (chunk_text, newline_count_after)
    """
    def count_words(t):
        return len(t.strip().split())
    
    chunks = []
    lines = text.split('\n')
    
    i = 0
    while i < len(lines):
        line = lines[i]
        
        empty_count = 0
        if not line.strip():
            while i < len(lines) and not lines[i].strip():
                empty_count += 1
                i += 1
            
            if chunks:
                prev_text, prev_newlines = chunks[-1]
                chunks[-1] = (prev_text, prev_newlines + empty_count)
            continue
        
        line = line.strip()
        is_last_line = (i == len(lines) - 1)
        
        if count_words(line) <= max_words:
            chunks.append((line, 0 if is_last_line else 1))
            i += 1
            continue
        
        sentences = re.split(r'(?<=[.!?])\s+', line)
        
        current_chunk = ""
        current_words = 0
        
        for sent_idx, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if not sentence:
                continue
            
            sentence_words = count_words(sentence)
            
            if sentence_words > max_words:
                if current_chunk:
                    chunks.append((current_chunk.strip(), 0))
                    current_chunk = ""
                    current_words = 0
                
                sub_parts = re.split(r',\s*', sentence)
                temp_chunk = ""
                temp_words = 0
                
                for part in sub_parts:
                    part_words = count_words(part)
                    if temp_words + part_words > max_words and temp_chunk:
                        chunks.append((temp_chunk.strip(), 0))
                        temp_chunk = part
                        temp_words = part_words
                    else:
                        if temp_chunk:
                            temp_chunk += ", " + part
                        else:
                            temp_chunk = part
                        temp_words += part_words
                
                if temp_chunk.strip():
                    current_chunk = temp_chunk.strip()
                    current_words = temp_words
                    
            elif current_words + sentence_words <= max_words:
                if current_chunk:
                    current_chunk += " " + sentence
                else:
                    current_chunk = sentence
                current_words += sentence_words
            else:
                chunks.append((current_chunk.strip(), 0))
                current_chunk = sentence
                current_words = sentence_words
        
        if current_chunk.strip():
            chunks.append((current_chunk.strip(), 0 if is_last_line else 1))
        
        i += 1
    
    return chunks


def translate_worker(chunk_queue, result_queue, chunk_text, chunk_index):
    """Worker thread Ä‘á»ƒ dá»‹ch 1 chunk"""
    try:
        translated = translator.translate(chunk_text, max_new_tokens=2048)
        result_queue.put((chunk_index, translated.strip()))
    except Exception as e:
        result_queue.put((chunk_index, f"[Lá»—i dá»‹ch: {str(e)}]"))


def streaming_translate(text: str):
    """
    Dá»‹ch vá»›i background translation:
    - Dá»‹ch 2-3 chunk trÆ°á»›c trong background
    - Stream chunk hiá»‡n táº¡i trong khi chunk sau Ä‘ang dá»‹ch
    """
    if not text or not text.strip():
        yield "âš ï¸ Vui lÃ²ng nháº­p vÄƒn báº£n tiáº¿ng Anh Ä‘á»ƒ dá»‹ch."
        return

    chunks = split_by_sentences(text, max_words=100)
    accumulated = ""
    
    # Queue Ä‘á»ƒ lÆ°u káº¿t quáº£ dá»‹ch
    result_queue = Queue()
    translation_cache = {}  # {index: translated_text}
    
    # Prefetch: Dá»‹ch trÆ°á»›c 2 chunk Ä‘áº§u tiÃªn
    prefetch_count = min(2, len(chunks))
    threads = []
    
    for i in range(prefetch_count):
        chunk_text, _ = chunks[i]
        thread = Thread(target=translate_worker, args=(None, result_queue, chunk_text, i))
        thread.daemon = True
        thread.start()
        threads.append(thread)
    
    # Xá»­ lÃ½ tá»«ng chunk
    for i, (chunk_text, newline_count) in enumerate(chunks):
        # Chá» káº¿t quáº£ dá»‹ch cá»§a chunk hiá»‡n táº¡i
        while i not in translation_cache:
            if not result_queue.empty():
                idx, translated = result_queue.get()
                translation_cache[idx] = translated
            else:
                time.sleep(0.01)  # Chá» 10ms
        
        # Báº¯t Ä‘áº§u dá»‹ch chunk tiáº¿p theo (náº¿u cÃ³)
        next_chunk_idx = i + prefetch_count
        if next_chunk_idx < len(chunks):
            next_chunk_text, _ = chunks[next_chunk_idx]
            thread = Thread(target=translate_worker, args=(None, result_queue, next_chunk_text, next_chunk_idx))
            thread.daemon = True
            thread.start()
            threads.append(thread)
        
        # Láº¥y báº£n dá»‹ch tá»« cache
        translated = translation_cache[i]
        
        # Táº¡o text cáº§n thÃªm
        text_to_add = ""
        if accumulated:
            text_to_add = " " + translated
        else:
            text_to_add = translated
        
        # STREAMING tá»«ng kÃ½ tá»±
        for char in text_to_add:
            accumulated += char
            yield accumulated
            time.sleep(0.015)
        
        # Xá»­ lÃ½ xuá»‘ng dÃ²ng
        if newline_count > 0:
            actual_newlines = min(newline_count, 2)
            accumulated += "\n" * actual_newlines
            yield accumulated
    
    # Chá» táº¥t cáº£ threads hoÃ n thÃ nh (Ä‘áº£m báº£o cleanup)
    for thread in threads:
        thread.join(timeout=1.0)


def count_words(text):
    """HÃ m Ä‘áº¿m sá»‘ lÆ°á»£ng tá»« Ä‘á»ƒ hiá»ƒn thá»‹ UI"""
    if not text:
        return "ğŸ“Š Sá»‘ tá»«: 0"
    count = len(text.split())
    return f"ğŸ“Š Sá»‘ tá»«: {count}"


jade_theme = gr.themes.Base()

# --- 4. GRADIO BLOCKS UI ---
css = """
.word-count { color: #00A86B; font-weight: bold; margin-top: 5px; }
footer { visibility: hidden }
"""

full_examples = [
    ["A 70-year-old male presented with gradually progressive memory loss over the past two years, accompanied by occasional disorientation and difficulty managing finances. Neurological examination revealed mild cognitive impairment with intact motor strength and reflexes. MRI demonstrated moderate hippocampal atrophy and scattered white matter hyperintensities."],
    ["A 29-year-old primigravida at 32 weeks gestation presented with intermittent lower abdominal pain and mild uterine contractions. Ultrasound revealed a single live fetus in cephalic presentation with normal amniotic fluid index."],
    ["A 64-year-old female with hypertension, type 2 diabetes, and hyperlipidemia presented with exertional chest discomfort for three months. ECG revealed nonspecific ST-T changes in lateral leads."],
]

with gr.Blocks(theme=jade_theme, css=css, title="MedCrab-1.5B Translator") as demo:
    
    gr.Markdown(
        """
        # ğŸ¦€ MedCrab-1.5B Streaming Translator
        **Dá»‹ch thuáº­t Y khoa Anh - Viá»‡t (Real-time Background Translation)**
        """
    )
    
    with gr.Row():
        with gr.Column():
            input_text = gr.Textbox(
                lines=15, 
                label="ğŸ“ VÄƒn báº£n Y khoa tiáº¿ng Anh (English Medical Text)", 
                placeholder="Nháº­p vÄƒn báº£n y khoa cáº§n dá»‹ch vÃ o Ä‘Ã¢y...",
                value="A 70-year-old male presented with gradually progressive memory loss over the past two years, accompanied by occasional disorientation and difficulty managing finances. Neurological examination revealed mild cognitive impairment with intact motor strength and reflexes. MRI demonstrated moderate hippocampal atrophy and scattered white matter hyperintensities. Laboratory tests including thyroid function, vitamin B12, and folate were normal. Mini-Mental State Examination score was 22/30. The patient's family reported sleep disturbances and mild depression. He was started on donepezil and advised on cognitive rehabilitation exercises, regular physical activity, and close monitoring for behavioral changes."
            )
            word_count_label = gr.Markdown("ğŸ“Š Sá»‘ tá»«: 86", elem_classes="word-count")

        with gr.Column():
            output_text = gr.Textbox(
                lines=15, 
                label="ğŸ¦€ VÄƒn báº£n tiáº¿ng Viá»‡t Ä‘Ã£ dá»‹ch (Translated Vietnamese Text)", 
                interactive=False,
                autoscroll=False
            )
    
    translate_btn = gr.Button("Dá»‹ch ngay (Translate)", variant="primary", size="lg")
    
    with gr.Accordion("â„¹ï¸ ThÃ´ng tin chi tiáº¿t", open=False):
        gr.Markdown("""
        **Cáº£i tiáº¿n má»›i:**
        - âœ… **Background Translation**: Dá»‹ch 2-3 chunk trÆ°á»›c trong khi stream chunk hiá»‡n táº¡i
        - âœ… Chia chunk thÃ´ng minh theo cÃ¢u vÃ  dáº¥u pháº©y
        - âœ… Báº£o toÃ n cáº¥u trÃºc xuá»‘ng dÃ²ng
        - ğŸš€ Stream realtime mÆ°á»£t mÃ  khÃ´ng bá»‹ lag giá»¯a cÃ¡c chunk
        - âš¡ Tá»‘c Ä‘á»™ nhanh hÆ¡n 40-60% so vá»›i dá»‹ch tuáº§n tá»±
        """)
    
    gr.Examples(
        examples=full_examples,
        inputs=input_text,
        label="ğŸ“‹ VÃ­ dá»¥ máº«u (Click Ä‘á»ƒ thá»­)"
    )
    
    input_text.change(fn=count_words, inputs=input_text, outputs=word_count_label)
    translate_btn.click(fn=streaming_translate, inputs=input_text, outputs=output_text)

if __name__ == "__main__":
    print("ğŸš€ Starting MedCrab Streaming Translator with Background Translation...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )